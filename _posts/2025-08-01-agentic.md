---
title: "Agentic AI Models"
date: "2025-08-01 00:00:00 -0600"
tags: [ML, Machine Learning]
image:
  path: https://res.cloudinary.com/de8dxxflb/image/upload/c_pad,w_1200,h_630/v1754058464/agentic_models_uocjrb.png
  alt: ""
description: ""
categories: [Machine Learning]
author: Zak
---

## üí¨ Overview

**Agentic AI models** are systems, often powered by large language models (LLMs), that are designed to operate autonomously in pursuit of a goal. Rather than simply responding to prompts, these agents take initiative: they plan actions, execute them (such as calling tools or APIs), observe the outcomes, and iterate based on feedback.

A typical agent breaks a complex task into manageable steps, choose appropriate tools (like web search or code execution), and loop through this cycle repeatedly, refining its approach as it goes. These models maintain their own chain of thought and continue working without requiring new human input at every turn.

![World Wide Agentic AI Search Topic](https://res.cloudinary.com/de8dxxflb/image/upload/v1754066465/agentic_search_rxxz40.png){: w="650" }
*üåç Worldwide Search Trend: Agentic AI Topic (Jan 2023 - July 2025)*

Interest in agentic AI has grown rapidly as these systems begin to show real-world potential. The chart above illustrates the rise in global search interest for the topic of ‚ÄúAgentic AI‚Äù from early 2023 through mid-2025.


## üí° Example Applications

**Virtual Research Assistants**: Agentic models like AutoGPT can autonomously gather and summarize information. For example, perform market research-searching the web, analyzing product reviews, and then writing a polished summary with minimal human intervention.

**Agents in Simulated Environments**: Agentic systems can also live inside virtual worlds and learn on their own. For example, [Voyager](https://arxiv.org/abs/2305.16291) used GPT-4 to explore Minecraft independently-writing and refining code, building a skill library, and mastering mining, crafting, and survival through repeated interaction with the environment.

![Hello World Minecraft](https://res.cloudinary.com/de8dxxflb/image/upload/v1754078710/minecraft_ril2do.png){: w="350" }

**Autonomous Code Manager**:  Agents such as Devin act like self-directed junior developers. They can navigate codebases, fix bugs, implement features, and even deploy apps. Devin has been shown to autonomously resolve real GitHub issues and manage workflows end-to-end with little supervision.

---

### ü§ñ How Are Agentic Models Different from Traditional LLMs?

**Autonomy**: A normal LLM won‚Äôt do anything unless prompted each time. It answers your question and stops there. An agentic AI, in contrast, will  continue working toward a goal without needing new instructions at every step

**Long-Term Memory**: Out-of-the-box, most LLMs are amnesiacs. They only remember what‚Äôs in the current chat (and even that is limited by the context length). If the conversation resets, all is forgotten. Agentic systems tackle this by giving the AI longer-term memory

**Taking Action**: Traditional LLMs live in a text-only world. They produce an answer, but they cannot directly act on external systems. Agentic models are designed to take actions.

**Planning**: When you prompt a LLM with a complex problem, it will try to solve it in one go (perhaps with some chain-of-thought). Agentic AIs make planning explicit.

**Iterative Self-Improvement**: Because they operate in a loop, agentic systems can learn from their mistakes on the fly. A static LLM, if it produces an incorrect answer, won‚Äôt know unless a human corrects it. But an agent can be built to notice failure signals (like an error message) and then adjust.

#### üß© Putting It Together: New Capabilities

Agentic models add persistence, initiative, tool-enabled actions, and iterative planning on top of what vanilla LLMs can do. These differences let agents tackle more complex, extended tasks. They also introduce new challenges (like keeping the agent focused, safe, and within bounds). Next, let‚Äôs peek under the hood at how these agents function.

### üîÑ Inside the Agent Loop

Most agentic AI systems share a common control flow. At their core is still an LLM ‚Äúbrain‚Äù deciding what to do, but now it‚Äôs embedded in a loop of `Plan ‚Üí Act ‚Üí Observe ‚Üí Reflect`.

![Plan ‚Üí Act ‚Üí Observe ‚Üí Reflect](https://res.cloudinary.com/de8dxxflb/image/upload/c_pad,w_700,h_400/v1754067867/agentic_loop_lq6eu4.png){: w="350" }

#### Pseudocode for an Agentic AI's Control Loop

```python
# 

# User-generated prompt
goal = "Make a dinner reservation at a nice Italian restaurant for 2 people at 6:30PM."

# Long-term memory of observations
memory = []  

# Main control loop
while True:

    # Plan: decide next action
    plan = agent.brain.plan_next_step(goal, memory) 

    # Act: perform the action
    action = agent.execute(plan)
    
    # Observe: capture the outcome
    result = environment.get_feedback(action) 
    
    # Remember: store in memory
    memory.append((plan, action, result)) 

    # Stop if goal is acheieved
    if agent.check_goal_completed(result):
        logger.info("Goal achieved!")
        break

    # Reflect: update strategy
    agent.brain.reflect(result, memory) 
```

On each iteration, the LLM is fed the current context. This context includes the overall goal, recent conversation or results, and a request. The LLM‚Äôs output typically contains both a thought (justification or reasoning) and an action command. For example, it might produce: `Thought: ‚ÄúI should search for relevant papers.‚Äù` `Action: SEARCH["latest research on X"]`. The agent framework parses that and actually executes the `SEARCH` action, then takes the returned results and feeds them back into the LLM on the next loop as an observation.

Crucially, the agent loop also involves updating memory and using feedback. The agent appends important results to its memory (which could simply be keeping past observations in the context window, or using a vector store for longer-term storage). The LLM can then recall earlier facts or adjust plans. If an action failed or returned an error, the next iteration can include that info, prompting the LLM to try a different approach. This iterative cycle continues, giving the agent multiple ‚Äúshots‚Äù at the problem instead of just one.

#### ‚öôÔ∏è Components of an LLM-based Agent

Here are some of the major components that make up an LLM-based agent:

- **LLM ‚ÄúReasoning Engine‚Äù (Planner)**: The core language model that plans the next action based on the current goal and memory.

- **Memory Store**: Many frameworks integrate a vector database for long-term memory. The agent can embed text (facts, observations) into a vector and store it, then later perform similarity search to recall relevant information when needed.

- **Tool/Action Interfaces**: These enable the agent to interact with external systems‚Äîsuch as search engines, APIs, or code execution environments.

- **Execution Loop & Controller**: The logic that orchestrated the agent. Essentially the code that implements the pseudocode shown above. It manages the flow of planning, acting, observing, and reflecting.

- **Goal and Task Management**: The agent maintains a list of active goals and subtasks, tracking progress and updating as needed.

All these pieces work in concert to create an agentic AI. If you peek into projects like [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT) or [BabyAGI](https://github.com/yoheinakajima/babyagi) on GitHub, you‚Äôll find these components reflected in the code: prompt templates for the LLM ‚Äúbrain,‚Äù classes for tools and actions, memory buffers or vector store integrations, and a loop driver.

---

## üóìÔ∏è Timeline

<article class="px-1">
  <div class="content">
    <div id="archives" class="pl-xl-3">

      <time class="year lead d-block">2023</time>
      <ul class="list-unstyled">
        <li>
          <span class="date day">28</span>
          <span class="date month small text-muted ms-1">Mar</span>
          <a href="https://twitter.com/yoheinakajima" target="_blank">
            BabyAGI (Yohei Nakajima): minimal GPT‚Äë4 + LangChain + Pinecone agent
          </a>
        </li>
        <li>
          <span class="date day">30</span>
          <span class="date month small text-muted ms-1">Mar</span>
          <a href="https://github.com/Significant-Gravitas/AutoGPT" target="_blank">
            AutoGPT (Toran Bruce Richards): open-source autonomous agent using GPT‚Äë4
          </a>
        </li>
        <li>
          <span class="date day">25</span>
          <span class="date month small text-muted ms-1">May</span>
          <a href="https://arxiv.org/abs/2305.16291" target="_blank">
            Voyager: LLM‚Äëpowered embodied lifelong‚Äëlearning agent in Minecraft
          </a>
        </li>
      </ul>

      <time class="year lead d-block">2024</time>
      <ul class="list-unstyled">
        <li>
          <span class="date day">12</span>
          <span class="date month small text-muted ms-1">Mar</span>
          <a href="https://cognition.ai/blog/introducing-devin" target="_blank">
            Devin: the world‚Äôs first fully autonomous AI software engineer (Cognition Labs)
          </a>
        </li>
      </ul>

      <time class="year lead d-block">2024</time>
      <ul class="list-unstyled">
        <li>
          <span class="date day">22</span>
          <span class="date month small text-muted ms-1">Jul</span>
          <a href="https://arxiv.org/abs/2407.15325" target="_blank">
            Odyssey: Open‚Äëworld skill learning agent in Minecraft (successor to Voyager)
          </a>
        </li>
      </ul>

    </div>
  </div>
</article>

---


## üì¶ Closing Thoughts

Agentic AI models have captured imaginations by hinting at a future where AI isn't just smart‚Äîbut goal-driven, proactive, and capable of taking initiative. The idea of simply saying, ‚ÄúPlease handle this project,‚Äù and having an agent autonomously plan, execute, and adapt is a powerful vision.  

But today‚Äôs agentic models are still in their early days. Reliability is a key challenge‚Äîagents often get stuck, lose track of tasks, or flounder without human input.

### üîë Key Takeaways
- **Action**: Agentic models don‚Äôt just respond; they take action. They plan and act on the environment to achieve objectives.
- **Reliability**: Agentic agents can steer toward goals, but today‚Äôs systems often falter without clearer memory, task tracking, and error handling.
- **Safety**: With agents that can act in the world we need deliberate guardrails such as tool whitelists, monitoring, and accountability frameworks to prevent misuse and manage risk.

As these systems mature, aligning autonomy with reliability and responsibility will continue to be essential.

---

‚òï [Buy me a coffee](https://www.buymeacoffee.com/znimon)
